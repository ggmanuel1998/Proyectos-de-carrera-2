{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Filtrado"
      ],
      "metadata": {
        "id": "Rnw0Qh6y-_bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import time\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import WordNetLemmatizer\n",
        "from string import punctuation\n",
        "from multiprocessing import Pool\n",
        "import spacy\n",
        "class Procesamiento:\n",
        "    def __init__(self,nombreArchivo,nombreHashtag):    \n",
        "      df=pd.read_csv(nombreArchivo,lineterminator='\\n')\n",
        "      df['tweet']=df['tweet'].apply(lambda x: str(x).lower())\n",
        "      print(f\"tamano del df {df.shape[0]}\")\n",
        "      print(f\"filtrando el archivo \\\"{nombreHashtag}\\\"\")\n",
        "    # format='%Y%m%d',\n",
        "      #df['newTime']=df['date'].astype(str) + 'T' + df['time'].astype(str)\n",
        "      #df['date'] = pd.to_datetime(df['date'] + ' ' + df['time'], errors='coerce')\n",
        "      #---df['date'] = pd.to_datetime(df['date']+' '+df['time'], errors='coerce')\n",
        "      self.tweets=df[[\"date\",\"time\",\"tweet\",\"language\",\"likes_count\"]].copy()\n",
        "\n",
        "      #retweets_count,likes_count,replies_count\n",
        "      self.tweets=self.tweets.sort_values(by=['likes_count'],ascending=False)\n",
        "      self.tweets=self.tweets[self.tweets['likes_count']>=0]\n",
        "      \"\"\"------------Filtrar tweets en ingles------------\"\"\"\n",
        "      \n",
        "      self.tweets=self.tweets[self.tweets['language']==\"en\"]\n",
        "      print(f\"tamano de solo palabras en ingles {self.tweets.shape[0]}\")\n",
        "      self.tweets.drop('language', axis=1, inplace=True)\n",
        "      \"\"\"------------Filtro caractestiticas Redes Sociales------------\"\"\"\n",
        "      #emojis\n",
        "      self.tweets['tweet']=self.tweets['tweet'].apply(lambda x: self.convert_emojis(str(x)))\n",
        "\n",
        "      self.corpus=self.tweets['tweet'].to_list()\n",
        "      #numeros\n",
        "      #self.corpus=[re.sub('[0-9]+', '', word) for word in self.corpus]\n",
        "      # enlaces paginas\n",
        "      self.corpus=[re.sub('http[s]?://\\S+', '', document) for document in self.corpus]\n",
        "\n",
        "      \"\"\"------------Normalizar y  tokenizar------------\"\"\"\n",
        "      #self.corpus=[ str(document).lower() for document in self.corpus]\n",
        "      \n",
        "      #tokenizar\n",
        "      self.corpus=[[word for word in str(document).split()] for document in self.corpus]\n",
        "      \"\"\"------------Punctuacion------------\"\"\"\n",
        "      my_punct = ['!', '\"', '$', '%', '&', '\\'', '(', ')', '*', '+', ',', '.','/', ':', ';', '<',\n",
        "                  '=', '>', '?', '[', '\\\\', ']', '^', '`', '{', '|', '}', '~', '»', '«',\n",
        "                  '“', '”','’','…','‘','\\\"','–']\n",
        "      my_punct+=['#','@','-','_']\n",
        "      punct_pattern = re.compile(\"[\" + re.escape(\"\".join(my_punct)) + \"]\")\n",
        "      self.corpus=[[re.sub(punct_pattern, \"\", word) for word in document] for document in self.corpus]\n",
        "      \"\"\"------------stopwords------------\"\"\"\n",
        "      #stopwords\n",
        "      palabrasEvitar=[\"ur\",\"ya\",\"of\",\"russia's\",\"russian\",\"dm\",\"rt\", \"via\", \"amp\",\n",
        "                      \"http\", \"https\", \"m\", \"re\", \"co\",\"-\",\"--\",\n",
        "                      f\"#{str(nombreHashtag).lower()}\",str(nombreHashtag[1:]).lower()]\n",
        "      palabrasAdicionales=[\"#wwdc22\",\"qatar\"]\n",
        "      stop_words=[]\n",
        "      with open(\"/content/drive/MyDrive/Proyectos 2/CODE/stopwords.txt\", \"r\") as sw:\n",
        "        for line in sw:\n",
        "          stop_words.append(line.strip())\n",
        "\n",
        "\n",
        "      stop_words+=palabrasEvitar\n",
        "      stop_words+=palabrasAdicionales\n",
        "\n",
        "      self.corpus=[[word for word in document if word not in stop_words] for document in self.corpus]\n",
        "      \"\"\"------------Lemmatizer------------\"\"\"\n",
        "      wnl = WordNetLemmatizer()\n",
        "      self.corpus=[[wnl.lemmatize(word) for word in document] for document in self.corpus]\n",
        "\n",
        "      self.corpus=[' '.join(document) for document in self.corpus]\n",
        "      #---------------- GUARDAR RESULTADO\n",
        "      self.export()\n",
        "      nombreExportar=nombreArchivo[0:-(len(nombreHashtag)+9)]\n",
        "      print(f\"exportando a {nombreExportar}procesado/{nombreHashtag}Proc.csv\")\n",
        "      self.tweets.to_csv(f\"{nombreExportar}procesado/{nombreHashtag}Proc.csv\", encoding='utf-8',index=False)\n",
        "    def convert_emojis(self,string):\n",
        "      emoji_pattern = re.compile(\"[\"\n",
        "                                u\"\\U0001F600-\\U0001F64F\"  \n",
        "                                u\"\\U0001F300-\\U0001F5FF\"  \n",
        "                                u\"\\U0001F680-\\U0001F6FF\"  \n",
        "                                u\"\\U0001F1E0-\\U0001F1FF\"  \n",
        "                                u\"\\U00002500-\\U00002BEF\"  \n",
        "                                u\"\\U00002702-\\U000027B0\"\n",
        "                                u\"\\U00002702-\\U000027B0\"\n",
        "                                u\"\\U000024C2-\\U0001F251\"\n",
        "                                u\"\\U0001f926-\\U0001f937\"\n",
        "                                u\"\\U00010000-\\U0010ffff\"\n",
        "                                u\"\\u2640-\\u2642\"\n",
        "                                u\"\\u2600-\\u2B55\"\n",
        "                                u\"\\u200d\"\n",
        "                                u\"\\u23cf\"\n",
        "                                u\"\\u23e9\"\n",
        "                                u\"\\u231a\"\n",
        "                                u\"\\ufe0f\"  \n",
        "                                u\"\\u3030\"\n",
        "                                \"]+\", flags=re.UNICODE)\n",
        "      return emoji_pattern.sub(r'', string)\n",
        "    def export(self):\n",
        "\n",
        "      #self.corpus=[[word for word in document]for document in self.corpus]\n",
        "      \n",
        "      self.tweets['tweetFiltrado']=self.corpus\n",
        "      naRows=list(self.tweets[self.tweets['tweetFiltrado'] == ''].index)\n",
        "      print(f\"Tamanio filas : {self.tweets.shape[0]}\")\n",
        "      if naRows:\n",
        "        print(f\"Se encontraron {len(naRows)} vacios \")\n",
        "        self.tweets.drop(naRows, axis=0, inplace=True)\n",
        "        print(f\"Tamanio filas : {self.tweets.shape[0]}\")\n",
        "\n",
        "\n",
        "      "
      ],
      "metadata": {
        "id": "mXIdljkT86pe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b668d2da-be56-4971-f1f2-739a5ccafbb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filtrado"
      ],
      "metadata": {
        "id": "354RSxbT5Lry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir=\"/content/drive/MyDrive/Proyectos 2/CODE/data/\"\n",
        "hashtags=[\"#russia\",\"#texas\",\"#WWDC\",\"qatar\"]\n",
        "\n",
        "print(\"*********\\t FILTRADO \\t*********\")\n",
        "for file in hashtags:\n",
        "  start_time = time.time()\n",
        "  result=Procesamiento(dir+file+\".csv\",file)\n",
        "  print(f\"Tiempo: {time.time() - start_time} segundos\")\n",
        "  #result.tweets.head(10)\n",
        "  print(\"-\"*12)"
      ],
      "metadata": {
        "id": "L1vehY-992me",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "455646f3-3a41-47fd-92a9-a8f65553677d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*********\t FILTRADO \t*********\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-c4c0387436d0>:7: DtypeWarning: Columns (9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  result=Procesamiento(dir+file+\".csv\",file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tamano del df 81938\n",
            "filtrando el archivo \"#russia\"\n",
            "tamano de solo palabras en ingles 57732\n",
            "Tamanio filas : 57732\n",
            "Se encontraron 32 vacios \n",
            "Tamanio filas : 57700\n",
            "exportando a /content/drive/MyDrive/Proyectos 2/CODE/procesado/#russiaProc.csv\n",
            "Tiempo: 27.909127473831177 segundos\n",
            "------------\n",
            "tamano del df 86971\n",
            "filtrando el archivo \"#texas\"\n",
            "tamano de solo palabras en ingles 59092\n",
            "Tamanio filas : 59092\n",
            "Se encontraron 134 vacios \n",
            "Tamanio filas : 58958\n",
            "exportando a /content/drive/MyDrive/Proyectos 2/CODE/procesado/#texasProc.csv\n",
            "Tiempo: 23.53804898262024 segundos\n",
            "------------\n",
            "tamano del df 76404\n",
            "filtrando el archivo \"#WWDC\"\n",
            "tamano de solo palabras en ingles 38942\n",
            "Tamanio filas : 38942\n",
            "exportando a /content/drive/MyDrive/Proyectos 2/CODE/procesado/#WWDCProc.csv\n",
            "Tiempo: 8.750253438949585 segundos\n",
            "------------\n",
            "tamano del df 497061\n",
            "filtrando el archivo \"qatar\"\n",
            "tamano de solo palabras en ingles 178266\n",
            "Tamanio filas : 178266\n",
            "Se encontraron 402 vacios \n",
            "Tamanio filas : 177864\n",
            "exportando a /content/drive/MyDrive/Proyectos 2/CODE/procesado/qatarProc.csv\n",
            "Tiempo: 70.2190887928009 segundos\n",
            "------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/Proyectos 2/CODE/procesado/qatarProc.csv\",lineterminator='\\n')\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ3Oa091LTSp",
        "outputId": "8dccc668-08f6-4c9f-e540-3efaeb40afa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(177864, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jW39nERShwr8",
        "outputId": "59da2b66-c519-49f2-d457-036813689aeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date      time                                              tweet  \\\n",
              "0  2022-12-01  08:19:07  great to be in qatar for the #worldcup2022.  t...   \n",
              "1  2022-12-02  12:16:05  qatar really cooked up one of the best world c...   \n",
              "2  2022-12-02  12:05:16  nah man qatar cooked us the best world cup gro...   \n",
              "3  2022-12-01  16:01:16  @qatari @thfckei because focusing on football ...   \n",
              "4  2022-11-30  12:03:13  im organising flying my bugatti from dubai to ...   \n",
              "\n",
              "   likes_count                                      tweetFiltrado  \n",
              "0       298268  great worldcup2022 great hospitality perfect o...  \n",
              "1       163719                              cooked best world cup  \n",
              "2        92607          nah man cooked best world cup group stage  \n",
              "3        73393                   qatari thfckei focusing football  \n",
              "4        72414  organising flying bugatti dubai turning world ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f959024-7179-4abf-85a3-81473b4fbf33\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>time</th>\n",
              "      <th>tweet</th>\n",
              "      <th>likes_count</th>\n",
              "      <th>tweetFiltrado</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-12-01</td>\n",
              "      <td>08:19:07</td>\n",
              "      <td>great to be in qatar for the #worldcup2022.  t...</td>\n",
              "      <td>298268</td>\n",
              "      <td>great worldcup2022 great hospitality perfect o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-12-02</td>\n",
              "      <td>12:16:05</td>\n",
              "      <td>qatar really cooked up one of the best world c...</td>\n",
              "      <td>163719</td>\n",
              "      <td>cooked best world cup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-12-02</td>\n",
              "      <td>12:05:16</td>\n",
              "      <td>nah man qatar cooked us the best world cup gro...</td>\n",
              "      <td>92607</td>\n",
              "      <td>nah man cooked best world cup group stage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-12-01</td>\n",
              "      <td>16:01:16</td>\n",
              "      <td>@qatari @thfckei because focusing on football ...</td>\n",
              "      <td>73393</td>\n",
              "      <td>qatari thfckei focusing football</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-11-30</td>\n",
              "      <td>12:03:13</td>\n",
              "      <td>im organising flying my bugatti from dubai to ...</td>\n",
              "      <td>72414</td>\n",
              "      <td>organising flying bugatti dubai turning world ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f959024-7179-4abf-85a3-81473b4fbf33')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f959024-7179-4abf-85a3-81473b4fbf33 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f959024-7179-4abf-85a3-81473b4fbf33');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}